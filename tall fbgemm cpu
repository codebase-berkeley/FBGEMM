[1mdiff --git a/fbgemm_gpu/test/tbe/inference/nbit_forward_test.py b/fbgemm_gpu/test/tbe/inference/nbit_forward_test.py[m
[1mindex a5ee8d6d..56cb8b8a 100644[m
[1m--- a/fbgemm_gpu/test/tbe/inference/nbit_forward_test.py[m
[1m+++ b/fbgemm_gpu/test/tbe/inference/nbit_forward_test.py[m
[36m@@ -1203,7 +1203,7 @@[m [mclass NBitFowardTest(unittest.TestCase):[m
         raw_embedding_weights = quant_cc.split_embedding_weights()[m
         # we mimic 1.0 scale, 0.0 bias for better results comparison[m
         embedding_weights: List[Tuple[torch.Tensor, Optional[torch.Tensor]]] = [[m
[31m-            (table_weight, torch.tensor([1, 0], dtype=torch.float16).view(torch.uint8))[m
[32m+[m[32m            (table_weight, None)[m
             for table_weight, _ in raw_embedding_weights[m
         ][m
         # Initialize the random weights for int8 nbit table split embedding bag[m
